{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/nicolo_b/Desktop/PhD/IFX/Notebooks/deepLearning/TRANSFER_LEARNING_JOURNAL_PAPER\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import nn_models\n",
    "from nn_models import *\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from parse import *\n",
    "\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 3\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "`make_regression()` function from the `sklearn.datasets` module is used to create sample data\n",
    "\n",
    "This code will generate a dataset with 1,000,000 samples and 27 features. The `effective_rank` parameter controls the linear dependency between the features, and the `n_informative` parameter determines the number of informative features. The `noise` parameter adds random noise to the data. The resulting dataset will be stored in the `X` variable.\n",
    "\n",
    "Skip the cell if data are already generate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _  = make_regression(n_samples=1000000, n_features=27, effective_rank = 14, n_informative=27, noise=0.1, random_state=SEED)\n",
    "\n",
    "# add non_linearity to mimic polynomial features interactions\n",
    "ground_truth = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(2)),\n",
    "    ('pca', PCA(1,random_state=SEED)),\n",
    "])\n",
    "\n",
    "y = ground_truth.fit_transform(X).reshape(-1)\n",
    "y = MinMaxScaler().fit_transform(y.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "\n",
    "np.save(f'X_{SEED}.npy', X)\n",
    "np.save(f'y_{SEED}.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "To load the numpy data, use the `np.load()` function:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f'X_{SEED}.npy')\n",
    "y = np.load(f'y_{SEED}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Train and test split\n",
    "Add shift and noise to A2 to mimic data from different product\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_A1, X_A2, y_A1, y_A2 = train_test_split(X, y, test_size=0.005, random_state=SEED)\n",
    "\n",
    "# add to A2 some noise, to mimic a shift in the distributions\n",
    "y_A2 = y_A2 + np.random.normal(5,0.01,len(y_A2))\n",
    "\n",
    "\n",
    "X_A1_train, X_A1_test, y_A1_train, y_A1_test = train_test_split(X_A1, y_A1, test_size=0.01, random_state=SEED)\n",
    "X_A2_train, X_A2_test, y_A2_train, y_A2_test = train_test_split(X_A2, y_A2, test_size=0.95, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f'./checkpoints'\n",
    "checkpoint_name_fe = 'SoftOrdering_PL_FE.ckpt'\n",
    "checkpoint_name_fe_ae = 'SoftOrdering_AE_FE.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Define the parameters of the NNs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {'input_dim':27,\n",
    "        'sign_size':32,\n",
    "        'cha_input':32,\n",
    "        'cha_hidden':32,\n",
    "        'K':2,\n",
    "        'dropout_input':0.1,\n",
    "        'dropout_hidden':0.1,\n",
    "        'dropout_output':0.1}\n",
    "\n",
    "parameter_dict_ae = {'input_dim':27,\n",
    "        'sign_size':32,\n",
    "        'cha_input':32,\n",
    "        'cha_hidden':64,\n",
    "        'K':4,\n",
    "        'dropout_input':0.2,\n",
    "        'dropout_hidden':0.2,\n",
    "        'dropout_output':0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Train the NNs on data from product A1, with abdundance of data.\n",
    "Skip if .ckpt was already generated\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SoftOrderingTrasnformer(SoftOrdering1DCNN,parameter_dict,pre_trained_ckpt=None,\n",
    "                                               device='cuda',allow_training=True,batch_size=256,\n",
    "                                              val_ratio=0.15,random_state=42,callbacks = \n",
    "                 [EarlyStopping(monitor='valid_loss',min_delta=.00001,patience=30,verbose=True,mode='min')],\n",
    "                 epochs=100)\n",
    "\n",
    "reg = Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('transformer',transformer),\n",
    "        ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "        ])\n",
    "\n",
    "reg.fit(X_A1_train,y_A1_train)\n",
    "print()\n",
    "transformer.freeze()\n",
    "with torch.no_grad():\n",
    "        print(f'Transformer score on A1: {reg.score(X_A1_test,y_A1_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Save the .ckpt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SoftOrderingTrasnformer(allow_training=True, batch_size=256,\n",
       "                        callbacks=[&lt;pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7fc5fc095220&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc5fc0274f0&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7fc5fc027340&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler object at 0x7fc5fc027070&gt;],\n",
       "                        device=&#x27;cuda&#x27;,\n",
       "                        parameter_dict={&#x27;K&#x27;: 2, &#x27;cha_hidden&#x27;: 32,\n",
       "                                        &#x27;cha_input&#x27;: 32, &#x27;dropout_hidden&#x27;: 0.1,\n",
       "                                        &#x27;dropout_input&#x27;: 0.1,\n",
       "                                        &#x27;dropout_output&#x27;: 0.1, &#x27;input_dim&#x27;: 27,\n",
       "                                        &#x27;sign_size&#x27;: 32},\n",
       "                        transformer_class=&lt;class &#x27;nn_models.SoftOrdering1DCNN&#x27;&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SoftOrderingTrasnformer</label><div class=\"sk-toggleable__content\"><pre>SoftOrderingTrasnformer(allow_training=True, batch_size=256,\n",
       "                        callbacks=[&lt;pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7fc5fc095220&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc5fc0274f0&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7fc5fc027340&gt;,\n",
       "                                   &lt;pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler object at 0x7fc5fc027070&gt;],\n",
       "                        device=&#x27;cuda&#x27;,\n",
       "                        parameter_dict={&#x27;K&#x27;: 2, &#x27;cha_hidden&#x27;: 32,\n",
       "                                        &#x27;cha_input&#x27;: 32, &#x27;dropout_hidden&#x27;: 0.1,\n",
       "                                        &#x27;dropout_input&#x27;: 0.1,\n",
       "                                        &#x27;dropout_output&#x27;: 0.1, &#x27;input_dim&#x27;: 27,\n",
       "                                        &#x27;sign_size&#x27;: 32},\n",
       "                        transformer_class=&lt;class &#x27;nn_models.SoftOrdering1DCNN&#x27;&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SoftOrderingTrasnformer(allow_training=True, batch_size=256,\n",
       "                        callbacks=[<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x7fc5fc095220>,\n",
       "                                   <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc5fc0274f0>,\n",
       "                                   <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7fc5fc027340>,\n",
       "                                   <pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler object at 0x7fc5fc027070>],\n",
       "                        device='cuda',\n",
       "                        parameter_dict={'K': 2, 'cha_hidden': 32,\n",
       "                                        'cha_input': 32, 'dropout_hidden': 0.1,\n",
       "                                        'dropout_input': 0.1,\n",
       "                                        'dropout_output': 0.1, 'input_dim': 27,\n",
       "                                        'sign_size': 32},\n",
       "                        transformer_class=<class 'nn_models.SoftOrdering1DCNN'>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = SEED\n",
    "transformer.save_ckpt(f'checkpoints/myckpt_{i}.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Test the NNs on product A2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformer score on A2: 0.9707414935039516\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name_fe = f'myckpt_{SEED}.ckpt'\n",
    "#checkpoint_name_fe = 'SoftOrdering_PL_FE.ckpt'\n",
    "\n",
    "transformer = SoftOrderingTrasnformer(SoftOrdering1DCNN,parameter_dict,pre_trained_ckpt=os.path.join(checkpoint_path,checkpoint_name_fe),\n",
    "                                               device='cuda',allow_training=False)\n",
    "\n",
    "transformer.transformer.load_state_dict(torch.load(os.path.join(checkpoint_path,checkpoint_name_fe)))\n",
    "\n",
    "transformer.freeze()\n",
    "\n",
    "reg = Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('transformer',transformer),\n",
    "        ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "        ])\n",
    "\n",
    "reg.fit(X_A2_train,y_A2_train)\n",
    "print()\n",
    "print(f'Transformer score on A2: {reg.score(X_A2_test,y_A2_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Benckmarks plus columns transformer to select specific or random columns (features adaptation)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_COLUMNS = np.arange(27)\n",
    "COLUMNS = np.arange(27)\n",
    "checkpoint_name_fe = f'myckpt_{SEED}.ckpt'\n",
    "transformer = SoftOrderingTrasnformer(SoftOrdering1DCNN,parameter_dict,pre_trained_ckpt=os.path.join(checkpoint_path,checkpoint_name_fe),\n",
    "                                               device='cuda',allow_training=False)\n",
    "regressors_dict = {\n",
    "    'Baseline': Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('PCA',PCA(14)),\n",
    "        ('transformer',PolynomialFeatures(2)),\n",
    "        ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "        ]),\n",
    "    'Dummy Voting CNN': VotingRegressor(\n",
    "        [(f'Dummy CNN {i}',Pipeline([\n",
    "            ('scaler',StandardScaler()),\n",
    "            ('selector',DummySelector(columns=COLUMNS,features_len=27)),\n",
    "            ('transformer',SoftOrderingTrasnformer(SoftOrdering1DCNN,parameter_dict,pre_trained_ckpt=os.path.join(checkpoint_path,checkpoint_name_fe),\n",
    "                                               device='cuda',allow_training=False)),                \n",
    "            ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))])) for i in range(10)],n_jobs=1),\n",
    "    \n",
    "    'SoftOrderingCNN' : Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('transformer',SoftOrderingTrasnformer(SoftOrdering1DCNN,parameter_dict,pre_trained_ckpt=os.path.join(checkpoint_path,checkpoint_name_fe),\n",
    "                                               device='cuda',allow_training=False)),\n",
    "    ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "    ]),\n",
    "    \n",
    "    'SoftOrderingCNN_AE' : Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('transformer',SoftOrderingTrasnformer(SoftOrdering1DCNN_AutoEncoder,parameter_dict_ae,pre_trained_ckpt=os.path.join(checkpoint_path,checkpoint_name_fe_ae),\n",
    "                                            device='cuda',allow_training=False)),\n",
    "    ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "    ]),         \n",
    "    \n",
    "    'KNN-5': Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('regressor',KNeighborsRegressor(n_neighbors=5,n_jobs=-1))\n",
    "        ]),\n",
    "    'RandomForest':\n",
    "        Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('regressor',RandomForestRegressor(n_estimators=100,n_jobs=-1))\n",
    "        ]),\n",
    "    'Linear Ridge': Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('regressor',RidgeCV(alphas=np.logspace(-6,6,2000)))\n",
    "        ]),\n",
    "\n",
    "    'Linear Reg': Pipeline([\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('regressor',LinearRegression())\n",
    "        ])\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 0.9685075582008883\n",
      "Baseline 0.9718647309529165\n",
      "Baseline 0.9665193066074514\n",
      "Baseline 0.9714035896436429\n",
      "Baseline 0.9692541417175766\n",
      "Baseline mean 0.9695098654244951\n",
      "Dummy Voting CNN 0.6374953573666304\n",
      "Dummy Voting CNN 0.7326906211827724\n",
      "Dummy Voting CNN 0.7047901202508885\n",
      "Dummy Voting CNN 0.6729858702793075\n",
      "Dummy Voting CNN 0.681729400373116\n",
      "Dummy Voting CNN mean 0.685938273890543\n",
      "SoftOrderingCNN 0.9796672415695569\n",
      "SoftOrderingCNN 0.9801398325300962\n",
      "SoftOrderingCNN 0.9767516075970913\n",
      "SoftOrderingCNN 0.9800413281351411\n",
      "SoftOrderingCNN 0.9795576181812651\n",
      "SoftOrderingCNN mean 0.9792315256026303\n",
      "SoftOrderingCNN_AE 0.36164159354709013\n",
      "SoftOrderingCNN_AE 0.3673916959180702\n",
      "SoftOrderingCNN_AE 0.3608142493327975\n",
      "SoftOrderingCNN_AE 0.31972331648860663\n",
      "SoftOrderingCNN_AE 0.3145578139308025\n",
      "SoftOrderingCNN_AE mean 0.34482573384347337\n",
      "KNN-5 0.3520814490146841\n",
      "KNN-5 0.3138142857951569\n",
      "KNN-5 0.29511320778828787\n",
      "KNN-5 0.2931626680743069\n",
      "KNN-5 0.33854878616750417\n",
      "KNN-5 mean 0.318544079367988\n",
      "RandomForest 0.6647674645296657\n",
      "RandomForest 0.6301144357106632\n",
      "RandomForest 0.6799450853582762\n",
      "RandomForest 0.6255032936533476\n",
      "RandomForest 0.6711688976462165\n",
      "RandomForest mean 0.6542998353796339\n",
      "Linear Ridge -0.0015572544071891237\n",
      "Linear Ridge -0.00010639374219678643\n",
      "Linear Ridge -0.002025056391660396\n",
      "Linear Ridge -0.00015988526768695444\n",
      "Linear Ridge -0.0002207445982662648\n",
      "Linear Ridge mean -0.000813866881399905\n",
      "Linear Reg -0.020760504866104812\n",
      "Linear Reg -0.013034626126383841\n",
      "Linear Reg -0.014664589844862963\n",
      "Linear Reg -0.010176818978083091\n",
      "Linear Reg -0.0036548918611474246\n",
      "Linear Reg mean -0.012458286335316426\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "mean_scores = defaultdict(list)\n",
    "for name,regr in regressors_dict.items():\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_A2,y_A2,test_size=0.2,random_state=i)\n",
    "        regr.fit(X_train,y_train)\n",
    "        y_prd = regr.predict(X_test)\n",
    "        mean_scores[name].append(r2_score(y_test,y_prd))\n",
    "        print(f'{name} {mean_scores[name][-1]}')\n",
    "    print(f'{name} mean {np.mean(mean_scores[name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R2: mean 0.9695 +- 0.0020 std\n",
      "Dummy Voting CNN R2: mean 0.6859 +- 0.0319 std\n",
      "SoftOrderingCNN R2: mean 0.9792 +- 0.0013 std\n",
      "SoftOrderingCNN_AE R2: mean 0.3448 +- 0.0228 std\n",
      "KNN-5 R2: mean 0.3185 +- 0.0234 std\n",
      "RandomForest R2: mean 0.6543 +- 0.0222 std\n",
      "Linear Ridge R2: mean -0.0008 +- 0.0008 std\n",
      "Linear Reg R2: mean -0.0125 +- 0.0056 std\n"
     ]
    }
   ],
   "source": [
    "for name,regr in regressors_dict.items():\n",
    "    print(f'{name} R2: mean {np.mean(mean_scores[name]):.4f} +- {np.std(mean_scores[name]):.4f} std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "CNNs based models offer a minor improvement over polynomial groundtruth baseline.\n",
    "The performance gain with respect to shallow-learning algorithm is not neglibile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-ifx38]",
   "language": "python",
   "name": "conda-env-anaconda3-ifx38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
